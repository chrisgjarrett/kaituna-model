{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import TimeSeriesSplit\nimport math\nfrom xgboost import XGBRegressor\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom statsmodels.tsa.deterministic import DeterministicProcess, CalendarFourier, Fourier\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import ElasticNet, Lasso, Ridge, LinearRegression\nfrom sklearn.preprocessing import MinMaxScaler\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.multioutput import MultiOutputRegressor, RegressorChain\nfrom sklearn.compose import make_column_selector\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import GridSearchCV","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-13T13:00:25.954214Z","iopub.execute_input":"2022-11-13T13:00:25.954593Z","iopub.status.idle":"2022-11-13T13:00:25.964795Z","shell.execute_reply.started":"2022-11-13T13:00:25.954562Z","shell.execute_reply":"2022-11-13T13:00:25.964023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create features and shift output\ndef make_lags(ts, lags, lead_time=1):\n    return pd.concat(\n        {\n            f'y_lag_{i}': ts.shift(i)\n            for i in range(lead_time, lags + lead_time)\n        },\n        axis=1)\n\ndef make_multistep_target(ts, steps):\n    return pd.concat(\n        {f'y_step_{i + 1}': ts.shift(-i)\n         for i in range(steps)},\n        axis=1)\n\ndef make_lags_transformer(n_lags):\n    return FunctionTransformer(lambda x: make_lags(x, n_lags))\n\n# Encode these as sine/cosine features to capture cyclical nature\ndef sin_transformer(period):\n    return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))\n\ndef cos_transformer(period):\n    return FunctionTransformer(lambda x: np.cos(x / period * 2 * np.pi))\n\ndef data_shift_transformer():\n    return FunctionTransformer(lambda x: x.dropna())","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:25.966345Z","iopub.execute_input":"2022-11-13T13:00:25.966640Z","iopub.status.idle":"2022-11-13T13:00:25.982222Z","shell.execute_reply.started":"2022-11-13T13:00:25.966613Z","shell.execute_reply":"2022-11-13T13:00:25.980683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Methods for feature engineering\ndef lagplot(x, y=None, lag=1, standardize=False, ax=None, **kwargs):\n    from matplotlib.offsetbox import AnchoredText\n    x_ = x.shift(lag)\n    if standardize:\n        x_ = (x_ - x_.mean()) / x_.std()\n    if y is not None:\n        y_ = (y - y.mean()) / y.std() if standardize else y\n    else:\n        y_ = x\n    corr = y_.corr(x_)\n    if ax is None:\n        fig, ax = plt.subplots()\n    scatter_kws = dict(\n        alpha=0.75,\n        s=3,\n    )\n    line_kws = dict(color='C3', )\n    ax = sns.regplot(x=x_,\n                     y=y_,\n                     scatter_kws=scatter_kws,\n                     line_kws=line_kws,\n                     lowess=True,\n                     ax=ax,\n                     **kwargs)\n    at = AnchoredText(\n        f\"{corr:.2f}\",\n        prop=dict(size=\"large\"),\n        frameon=True,\n        loc=\"upper left\",\n    )\n    at.patch.set_boxstyle(\"square, pad=0.0\")\n    ax.add_artist(at)\n    ax.set(title=f\"Lag {lag}\", xlabel=x_.name, ylabel=y_.name)\n    return ax\n\n\ndef plot_lags(x, y=None, lags=6, nrows=1, lagplot_kwargs={}, **kwargs):\n    import math\n    kwargs.setdefault('nrows', nrows)\n    kwargs.setdefault('ncols', math.ceil(lags / nrows))\n    kwargs.setdefault('figsize', (kwargs['ncols'] * 2, nrows * 2 + 0.5))\n    fig, axs = plt.subplots(sharex=True, sharey=True, squeeze=False, **kwargs)\n    for ax, k in zip(fig.get_axes(), range(kwargs['nrows'] * kwargs['ncols'])):\n        if k + 1 <= lags:\n            ax = lagplot(x, y, lag=k + 1, ax=ax, **lagplot_kwargs)\n            ax.set_title(f\"Lag {k + 1}\", fontdict=dict(fontsize=14))\n            ax.set(xlabel=\"\", ylabel=\"\")\n        else:\n            ax.axis('off')\n    plt.setp(axs[-1, :], xlabel=x.name)\n    plt.setp(axs[:, 0], ylabel=y.name if y is not None else x.name)\n    fig.tight_layout(w_pad=0.1, h_pad=0.1)\n    return fig\n\ndef plot_periodogram(ts, detrend='linear', ax=None):\n    from scipy.signal import periodogram\n    fs = pd.Timedelta(\"1Y\") / pd.Timedelta(\"1D\")\n    freqencies, spectrum = periodogram(\n        ts,\n        fs=fs,\n        detrend=detrend,\n        window=\"boxcar\",\n        scaling='spectrum',\n    )\n    if ax is None:\n        _, ax = plt.subplots()\n    ax.step(freqencies, spectrum, color=\"purple\")\n    ax.set_xscale(\"log\")\n    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n    ax.set_xticklabels(\n        [\n            \"Annual (1)\",\n            \"Semiannual (2)\",\n            \"Quarterly (4)\",\n            \"Bimonthly (6)\",\n            \"Monthly (12)\",\n            \"Biweekly (26)\",\n            \"Weekly (52)\",\n            \"Semiweekly (104)\",\n        ],\n        rotation=30,\n    )\n    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n    ax.set_ylabel(\"Variance\")\n    ax.set_title(\"Periodogram\")\n    return ax","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:25.984868Z","iopub.execute_input":"2022-11-13T13:00:25.985313Z","iopub.status.idle":"2022-11-13T13:00:26.005051Z","shell.execute_reply.started":"2022-11-13T13:00:25.985258Z","shell.execute_reply":"2022-11-13T13:00:26.004314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting helpers\nplot_params = dict(\n    color=\"0.75\",\n    style=\".-\",\n    markeredgecolor=\"0.25\",\n    markerfacecolor=\"0.25\",\n)\n%config InlineBackend.figure_format = 'retina'\n\n\ndef plot_multistep(y, every=1, ax=None, palette_kwargs=None):\n    palette_kwargs_ = dict(palette='husl', n_colors=16, desat=None)\n    if palette_kwargs is not None:\n        palette_kwargs_.update(palette_kwargs)\n    palette = sns.color_palette(**palette_kwargs_)\n    if ax is None:\n        fig, ax = plt.subplots()\n    ax.set_prop_cycle(plt.cycler('color', palette))\n    for date, preds in y[::every].iterrows():\n        preds.index = pd.period_range(start=date, periods=len(preds))\n        preds.plot(ax=ax)\n    return ax","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:26.006454Z","iopub.execute_input":"2022-11-13T13:00:26.007072Z","iopub.status.idle":"2022-11-13T13:00:26.030577Z","shell.execute_reply.started":"2022-11-13T13:00:26.007038Z","shell.execute_reply":"2022-11-13T13:00:26.029841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting helpers\nplot_params = dict(\n    color=\"0.75\",\n    style=\".-\",\n    markeredgecolor=\"0.25\",\n    markerfacecolor=\"0.25\",\n)\n%config InlineBackend.figure_format = 'retina'\n\n\ndef plot_multistep(y, every=1, ax=None, palette_kwargs=None):\n    palette_kwargs_ = dict(palette='husl', n_colors=16, desat=None)\n    if palette_kwargs is not None:\n        palette_kwargs_.update(palette_kwargs)\n    palette = sns.color_palette(**palette_kwargs_)\n    if ax is None:\n        fig, ax = plt.subplots()\n    ax.set_prop_cycle(plt.cycler('color', palette))\n    for date, preds in y[::every].iterrows():\n        preds.index = pd.period_range(start=date, periods=len(preds))\n        preds.plot(ax=ax)\n    return ax","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:26.046647Z","iopub.execute_input":"2022-11-13T13:00:26.046987Z","iopub.status.idle":"2022-11-13T13:00:26.071173Z","shell.execute_reply.started":"2022-11-13T13:00:26.046960Z","shell.execute_reply":"2022-11-13T13:00:26.069693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_pca(X, standardize=True):\n    # Standardize\n    if standardize:\n        X = (X - X.mean(axis=0)) / X.std(axis=0)\n    # Create principal components\n    pca = PCA()\n    X_pca = pca.fit_transform(X)\n    \n    # Convert to dataframe\n    component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n    X_pca = pd.DataFrame(X_pca, columns=component_names)\n    \n    # Create loadings\n    loadings = pd.DataFrame(\n        pca.components_.T,  # transpose the matrix of loadings\n        columns=component_names,  # so the columns are the principal components\n        index=X.columns,  # and the rows are the original features\n    )\n    return X_pca, loadings, pca\n\ndef apply_pca_transformer():\n    return FunctionTransformer(lambda x: apply_pca(x)[0])","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:26.073202Z","iopub.execute_input":"2022-11-13T13:00:26.073556Z","iopub.status.idle":"2022-11-13T13:00:26.085342Z","shell.execute_reply.started":"2022-11-13T13:00:26.073527Z","shell.execute_reply":"2022-11-13T13:00:26.084161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def round_to_nearest_n(data, rounding_level):\n    return rounding_level * round(data / rounding_level)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:26.086980Z","iopub.execute_input":"2022-11-13T13:00:26.087333Z","iopub.status.idle":"2022-11-13T13:00:26.103876Z","shell.execute_reply.started":"2022-11-13T13:00:26.087303Z","shell.execute_reply":"2022-11-13T13:00:26.102120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_mi_scores(X, y, discrete_features):\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\ndef plot_variance(pca, width=8, dpi=100):\n    # Create figure\n    fig, axs = plt.subplots(1, 2)\n    n = pca.n_components_\n    grid = np.arange(1, n + 1)\n    # Explained variance\n    evr = pca.explained_variance_ratio_\n    axs[0].bar(grid, evr)\n    axs[0].set(\n        xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0)\n    )\n    # Cumulative Variance\n    cv = np.cumsum(evr)\n    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n    axs[1].set(\n        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n    )\n    # Set up figure\n    fig.set(figwidth=8, dpi=100)\n    return axs","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:26.105848Z","iopub.execute_input":"2022-11-13T13:00:26.106312Z","iopub.status.idle":"2022-11-13T13:00:26.118147Z","shell.execute_reply.started":"2022-11-13T13:00:26.106270Z","shell.execute_reply":"2022-11-13T13:00:26.116697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preliminary Data Transforms","metadata":{}},{"cell_type":"code","source":"# Get data\nkaituna_data = pd.read_csv('../input/kaituna-20182022/kaituna_data_2018-01-01_2022-10-19.csv',parse_dates=[\"TimeStamp\"])\n\nkaituna_data[\"TimeStamp\"] = pd.to_datetime(kaituna_data['TimeStamp'], utc=True)\nkaituna_data = kaituna_data.set_index(\"TimeStamp\")\nkaituna_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:26.121172Z","iopub.execute_input":"2022-11-13T13:00:26.121568Z","iopub.status.idle":"2022-11-13T13:00:26.314232Z","shell.execute_reply.started":"2022-11-13T13:00:26.121532Z","shell.execute_reply":"2022-11-13T13:00:26.313170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Average gate level\nkaituna_data[\"AverageGate\"] = kaituna_data[[\"Gate1\", \"Gate2\", \"Gate3\"]].median(axis=1)\n\n# Average gate, rounded to the nearest 100\ngate_resolution_level = 100\nkaituna_data[\"AverageGateOrdinal\"] = round_to_nearest_n(kaituna_data[\"AverageGate\"], gate_resolution_level)\n\n\n# Extract hour, day, month, year from TimeStamp\nkaituna_data[\"Hour\"] = kaituna_data.index.hour\nkaituna_data[\"DayOfWeek\"] = kaituna_data.index.day_of_week\nkaituna_data[\"DayOfYear\"] = kaituna_data.index.dayofyear\nkaituna_data[\"Month\"] = kaituna_data.index.month\nkaituna_data[\"Year\"] = kaituna_data.index.year","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:26.315382Z","iopub.execute_input":"2022-11-13T13:00:26.315668Z","iopub.status.idle":"2022-11-13T13:00:26.348551Z","shell.execute_reply.started":"2022-11-13T13:00:26.315642Z","shell.execute_reply":"2022-11-13T13:00:26.347370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Define categorical columns\ncategorical_cols = ['Hour', 'DayOfWeek', 'Month', 'Year', 'AverageGateOrdinal']\nlevels = []\nfor col in categorical_cols:\n    kaituna_data[col] = kaituna_data[col].astype('int')\n\n#Numerical columns\nnumerical_cols = ['FlowRate','AverageGate','Rainfall','LakeLevel']","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:26.349867Z","iopub.execute_input":"2022-11-13T13:00:26.350473Z","iopub.status.idle":"2022-11-13T13:00:26.361345Z","shell.execute_reply.started":"2022-11-13T13:00:26.350439Z","shell.execute_reply":"2022-11-13T13:00:26.359782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration\nInitial data exploration - sanity checks and determining suitable features/outputs","metadata":{}},{"cell_type":"code","source":"# Exploration of variables\nsns.lineplot(x=kaituna_data.index,y=kaituna_data[\"AverageGate\"])\nplt.figure()\nsns.lineplot(x=kaituna_data.index,y=kaituna_data[\"AverageGateOrdinal\"])\nplt.figure()\nsns.lineplot(x=kaituna_data.index,y=kaituna_data[\"FlowRate\"])\nplt.figure()\nsns.lineplot(x=kaituna_data.index,y=kaituna_data[\"LakeLevel\"])\nplt.figure()\nsns.lineplot(x=kaituna_data.index,y=kaituna_data[\"Rainfall\"])\n\n\n# Visualise gate levels\nplt.figure()\npalette = ['tab:blue', 'tab:green', 'tab:red']\ngates_to_cumecs = sns.scatterplot(\n    x=kaituna_data[\"AverageGate\"], \n    y=kaituna_data[\"FlowRate\"], \n    #hue=kaituna_data[\"Year\"],\n    #palette='Set1'\n    )\nplt.ylabel('Flow rate (cumecs)')\nplt.xlabel(\"Gate Position\")\nplt.title(\"Kaituna Flow\")\nplt.show()\n\n# Investigate correlation of lake level and rainfall\nplt.figure()\npalette = ['tab:blue', 'tab:green', 'tab:red']\ngates_to_cumecs = sns.scatterplot(\n    x=kaituna_data[\"Rainfall\"], \n    y=kaituna_data[\"LakeLevel\"], \n    #hue=kaituna_data[\"Year\"],\n    #palette='Set1'\n    )\nplt.ylabel('LakeLevel')\nplt.xlabel(\"Rainfall\")\nplt.title(\"Kaituna Flow\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:26.363431Z","iopub.execute_input":"2022-11-13T13:00:26.363857Z","iopub.status.idle":"2022-11-13T13:00:40.611186Z","shell.execute_reply.started":"2022-11-13T13:00:26.363826Z","shell.execute_reply":"2022-11-13T13:00:40.610092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shape\ndisplay(kaituna_data.shape)\n\n# Describe\ndisplay(kaituna_data.describe())\n\n# Describe ordinal variables\n#print(kaituna_data[categorical_cols].describe())\ndisplay(kaituna_data.info())\n\ndisplay(kaituna_data.head())","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:40.612717Z","iopub.execute_input":"2022-11-13T13:00:40.613556Z","iopub.status.idle":"2022-11-13T13:00:40.686964Z","shell.execute_reply.started":"2022-11-13T13:00:40.613514Z","shell.execute_reply":"2022-11-13T13:00:40.685579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observations\n## Flow data and gate levels\nThis is highly seasonal. It appears that the primary trend is annual, peaking in winter and dipping in summer. However, it's not fully dependent on this, evidenced particularly by the latter months of 2022, where we had opens for several weeks.\n\n## Rainfall\nThe rainfall data initially looked suspicious - 75% of data was 0mm. I checked and double checked the data loading process and it looks correct. It is possible that, because it is hourly data, that there are many more hours where it doesn't rain, compared to when it does rain.\n\n## Case for predicting daily gate levels versus hourly\nGiven that so much rainfall data is actually 0, it may be preferable to try and predict the daily gate levels. This is actually favourable for a few reasons:\n\n1. Paddlers typically understand this more than flow rates.\n2. The gate levels, in my experience, rarely change in the course of a day/are set from the morning.\n\nIn saying this, if there is a gate change, say, in the afternoon, then it is possible that this will be missed by the algorithm. So let's begin with hourly and see how that goes","metadata":{}},{"cell_type":"markdown","source":"## Feature extraction","metadata":{}},{"cell_type":"code","source":"# Get features and target\n# Date features\ndate_features = [\n    #'Hour',\n    'DayOfWeek',\n    'Month'\n]\n\n#Numerical features\nnumerical_features = [\n    'Rainfall',\n    'LakeLevel',\n    'FlowRate'\n]\n\n#Categorical features\ncategorical_features = [\n    'AverageGateOrdinal'\n]\n\n#Combine to create the training data for the residuals model\nX_raw = kaituna_data[date_features + numerical_features + categorical_features]\n\ndisplay(X_raw.shape)\ndisplay(X_raw.head())\ndisplay(X_raw.info())","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:40.688364Z","iopub.execute_input":"2022-11-13T13:00:40.688734Z","iopub.status.idle":"2022-11-13T13:00:40.714473Z","shell.execute_reply.started":"2022-11-13T13:00:40.688699Z","shell.execute_reply":"2022-11-13T13:00:40.713732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Summarising into daily \n\nHaving initially tried hourly predictions, I quickly found two things:\n\n1. Rainfall data was hard to use as it was mostly 0s\n2. The number of timesteps predicting into the future were difficult to deal with and took a long time to train. \n\nDaily is perhaps more useful anyway, given how kayakers plan","metadata":{}},{"cell_type":"code","source":"def is_weekend(row):    \n    return (row['DayOfWeek'] == 5) or (row[\"DayOfWeek\"] == 6)\n\ndef aggregate_to_daily(hourly_data):\n    X_daily = hourly_data.groupby(by=hourly_data.index.date).agg(\n        Rainfall = ('Rainfall','sum'), \n        LakeLevel=('LakeLevel','mean'),\n        DayOfWeek = ('DayOfWeek', lambda x:x[0]),\n        Month = ('Month', lambda x:x[0]),\n        AverageGateOrdinal = ('AverageGateOrdinal', lambda x:pd.Series.mode(x)[0]),\n        FlowRate = ('FlowRate','median'),\n        #IsWeekend = ('DayOfWeek', lambda x: 1 if (pd.Series.mode(x) == 5.0) | (pd.Series.mode(x) == 6.0) else 0)\n    )\n\n    X_daily[\"IsWeekend\"] = X_daily.apply(is_weekend, axis=1)\n    \n    return X_daily\n\nX_daily = aggregate_to_daily(X_raw)\n\n#Set target variable\ntarget_column=\"FlowRate\"\n\nX_daily.index = pd.to_datetime(X_daily.index)\nX_daily.set_index(X_daily.index.to_period('D'), inplace=True)\n\ndisplay(X_daily.info())\ndisplay(X_daily.head())\n\nX_daily.to_csv('kaituna_daily.csv')","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:40.715573Z","iopub.execute_input":"2022-11-13T13:00:40.715865Z","iopub.status.idle":"2022-11-13T13:00:41.159157Z","shell.execute_reply.started":"2022-11-13T13:00:40.715839Z","shell.execute_reply":"2022-11-13T13:00:41.157774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exploration of variables\nplt.figure()\nX_daily[\"FlowRate\"].plot()\nplt.ylabel(\"Flow rate (cumecs)\")\n\nplt.figure()\nX_daily[\"LakeLevel\"].plot()\nplt.ylabel(\"Lake Level (m)\")\n\nplt.figure()\nsns.histplot(data=X_daily[\"Rainfall\"])\n\nplt.figure()\nX_daily[\"Rainfall\"].plot()\nplt.ylabel(\"Rainfall (mm)\")\n\n# Investigate correlation of lake level and rainfall\nplt.figure()\npalette = ['tab:blue', 'tab:green', 'tab:red']\ngates_to_cumecs = sns.scatterplot(\n    x=X_daily[\"Rainfall\"], \n    y=X_daily[\"LakeLevel\"], \n    #hue=X_daily[\"IsWeekend\"],\n    #palette='Set1'\n    )\nplt.ylabel('LakeLevel')\nplt.xlabel(\"Rainfall\")\nplt.title(\"LakeLevel x Rainfall\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:41.160559Z","iopub.execute_input":"2022-11-13T13:00:41.160972Z","iopub.status.idle":"2022-11-13T13:00:42.608466Z","shell.execute_reply.started":"2022-11-13T13:00:41.160933Z","shell.execute_reply":"2022-11-13T13:00:42.607105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Seasonal features","metadata":{}},{"cell_type":"code","source":"# Check seasonality\nplot_periodogram(X_daily[target_column])\n\n# Trend feature (unused currently)\ncalendar_fourier = CalendarFourier(freq=\"A\", order=1)#10 sin/cos pairs for \"A\"nnual seasonality\nfourier = Fourier(period=365.25*4, order=1)\n\n#Features for linear regression\ndp = DeterministicProcess(\n    index=X_daily.index,  # dates from the training data\n    constant=False,       # dummy feature for the bias (y_intercept)\n    order=0,             # the time dummy (trend)\n    additional_terms = [calendar_fourier],\n    drop=True,           # drop terms if necessary to avoid collinearity\n)\n\nX_seasonal_features = dp.in_sample()\ndisplay(X_seasonal_features.head())\n\nplt.figure()\ntest = X_seasonal_features.index.to_timestamp()\nplt.plot(test, X_seasonal_features.values)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:42.610711Z","iopub.execute_input":"2022-11-13T13:00:42.611569Z","iopub.status.idle":"2022-11-13T13:00:43.135332Z","shell.execute_reply.started":"2022-11-13T13:00:42.611531Z","shell.execute_reply":"2022-11-13T13:00:43.134299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Investigate if there is serial dependence\n_ = plot_lags(X_daily[target_column], lags=12, nrows=2)\n_ = plot_pacf(X_daily[target_column], lags=12)\n\n#As per https://www.kaggle.com/code/ryanholbrook/time-series-as-features, let's assume >0.1 is significant correlation ","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:43.138367Z","iopub.execute_input":"2022-11-13T13:00:43.139209Z","iopub.status.idle":"2022-11-13T13:00:46.230956Z","shell.execute_reply.started":"2022-11-13T13:00:43.139177Z","shell.execute_reply":"2022-11-13T13:00:46.230248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Mutual information","metadata":{}},{"cell_type":"markdown","source":"#### On flow rate","metadata":{}},{"cell_type":"code","source":"mi_scores = make_mi_scores(X_daily[[\"Rainfall\",\"LakeLevel\"]], X_daily[\"FlowRate\"], discrete_features=False)\nmi_scores","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:46.232003Z","iopub.execute_input":"2022-11-13T13:00:46.232603Z","iopub.status.idle":"2022-11-13T13:00:46.257405Z","shell.execute_reply.started":"2022-11-13T13:00:46.232578Z","shell.execute_reply":"2022-11-13T13:00:46.256535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that lake level contains much more information about the flowrate than the rainfall. ","metadata":{}},{"cell_type":"markdown","source":"#### On gate levels","metadata":{}},{"cell_type":"code","source":"mi_scores = make_mi_scores(X_daily[[\"Rainfall\",\"LakeLevel\"]], X_daily[\"AverageGateOrdinal\"], discrete_features=False)\nmi_scores","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:46.258450Z","iopub.execute_input":"2022-11-13T13:00:46.258691Z","iopub.status.idle":"2022-11-13T13:00:46.284204Z","shell.execute_reply.started":"2022-11-13T13:00:46.258668Z","shell.execute_reply":"2022-11-13T13:00:46.283189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Interestingly, lake level does not explain this as much, while rainfall explains it a bit more. This is possibly because the gate operators are predicting lake levels to rise based on rain","metadata":{}},{"cell_type":"markdown","source":"## PCA analysis","metadata":{}},{"cell_type":"code","source":"# Exploring potential for PCA\nX_pca_candidate = X_daily[[\"Rainfall\",\"LakeLevel\"]]\nX_pca_exploration,loadings, pca = apply_pca(X_pca_candidate)\n\ndisplay(loadings)\nplot_variance(pca);","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:46.285310Z","iopub.execute_input":"2022-11-13T13:00:46.285737Z","iopub.status.idle":"2022-11-13T13:00:46.614234Z","shell.execute_reply.started":"2022-11-13T13:00:46.285707Z","shell.execute_reply":"2022-11-13T13:00:46.612060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_rainfall_lake_level_ratio = X_daily[\"Rainfall\"] * X_daily[\"LakeLevel\"]\n\nsns.scatterplot(x=X_rainfall_lake_level_ratio, y=X_daily[\"FlowRate\"])\nX_rainfall_lake_level_ratio.head()\n\nplt.figure()\nX_rainfall_lakelevel_sum = X_daily[\"Rainfall\"] + X_daily[\"LakeLevel\"]\nsns.scatterplot(x=X_rainfall_lakelevel_sum, y=X_daily[\"FlowRate\"])\nX_rainfall_lakelevel_sum.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:46.615560Z","iopub.execute_input":"2022-11-13T13:00:46.615894Z","iopub.status.idle":"2022-11-13T13:00:47.009174Z","shell.execute_reply.started":"2022-11-13T13:00:46.615864Z","shell.execute_reply":"2022-11-13T13:00:47.008134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that there is potential for PCA features to provide information - i.e. there is some level of correlation (as expected) and PCA may be able to reduce the dimensionality of the problem.\n\nInterestingly, using the loadings to create a new feature has revealed that there are two distinct clusters, that seem to be separated by high/low FlowRate. However, this could be the consequence of different gate levels, as there are also other less distinct clusters below\n\nLet's examine the MI scores on each of the two candidate target variables","metadata":{}},{"cell_type":"code","source":"flowrate_mi_scores = make_mi_scores(X_pca_exploration, X_daily[\"FlowRate\"],discrete_features=False)\ngate_level_mi_scores = make_mi_scores(X_pca_exploration, X_daily[\"AverageGateOrdinal\"],discrete_features=False)\n\nprint(\"Flowrate Level MI:\")\ndisplay(flowrate_mi_scores)\nprint()\nprint(\"Gate Level MI:\")\ndisplay(gate_level_mi_scores)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:47.012597Z","iopub.execute_input":"2022-11-13T13:00:47.012954Z","iopub.status.idle":"2022-11-13T13:00:47.063502Z","shell.execute_reply.started":"2022-11-13T13:00:47.012928Z","shell.execute_reply":"2022-11-13T13:00:47.062556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In both cases, both PCA components have significant information about the target variable. This indicates that it may be beneficial to use PCA in the final model","metadata":{}},{"cell_type":"markdown","source":"### PCA with lag variables","metadata":{}},{"cell_type":"code","source":"# Create lags with pipeline\n\n# Days to look back\nn_rainfall_lags = 1\nn_lake_level_lags = 1\nn_target_lags = 1\n\n# Bundle preprocessing for data. We transform the date variables to cyclic, and make time series lags \n# for the lake level and rainfall data\nlag_generator = ColumnTransformer(\n    transformers=[\n        (\"target_lags\", make_lags_transformer(n_target_lags), [target_column]),\n        (\"rainfall_lags\", make_lags_transformer(n_rainfall_lags), [\"Rainfall\"]),\n        (\"lakelevel_lags\", make_lags_transformer(n_lake_level_lags), [\"LakeLevel\"]),       \n    ],\n)\n\nX_lag_features = lag_generator.fit_transform(X_daily)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:47.064905Z","iopub.execute_input":"2022-11-13T13:00:47.065231Z","iopub.status.idle":"2022-11-13T13:00:47.077147Z","shell.execute_reply.started":"2022-11-13T13:00:47.065200Z","shell.execute_reply":"2022-11-13T13:00:47.075297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert back to df\n# Get column names\ncolumn_prefixes = [\n    \"Target\",\n    \"Rainfall\",\n    \"LakeLevel\"]\n\ncolumn_names = []\n\ntemp_list = [column_prefixes[0] + \"_lag_{}\".format(i) for i in range(1,n_target_lags + 1)]\ncolumn_names.extend(temp_list)\n    \n# Rainfall lags\ntemp_list = [column_prefixes[1] + \"_lag_{}\".format(i) for i in range(1,n_rainfall_lags + 1)]\ncolumn_names.extend(temp_list)\n\n# Lake level lags\ntemp_list = [column_prefixes[2] + \"_lag_{}\".format(i) for i in range(1,n_lake_level_lags + 1)]\ncolumn_names.extend(temp_list)\n\"\"\"\nfor column_prefix in column_prefixes:\n    temp_list = [column_prefix + \"_lag_{}\".format(i) for i in range(1,n_lags + 1)]\n    column_names.extend(temp_list)\n\"\"\"\n#column_names.extend([\"Target_lag_1\"])\n\n# Create data frame\nX_lag_features_df = pd.DataFrame(X_lag_features, columns=column_names, index=X_daily.index)\n\ndisplay(X_lag_features_df.head())","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:47.080246Z","iopub.execute_input":"2022-11-13T13:00:47.080711Z","iopub.status.idle":"2022-11-13T13:00:47.096912Z","shell.execute_reply.started":"2022-11-13T13:00:47.080671Z","shell.execute_reply":"2022-11-13T13:00:47.095282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform PCA on the features - we know there is already potential to use this. Also the features are\n# likely to be highly correlated\nX_lags_pca_candidate = X_lag_features_df.dropna()\nX_lags_pca, loadings_lags, pca_lag = apply_pca(X_lags_pca_candidate)\n\ndisplay(loadings_lags)\nplot_variance(pca_lag);\n\n# MI scores for PCA components\npca_mi_scores = make_mi_scores(X_lags_pca, X_daily[target_column].loc[X_lags_pca_candidate.index],discrete_features=False)\n#gate_level_mi_scores = make_mi_scores(X_pca, y[\"AverageGateOrdinal\"],discrete_features=False)\n\ndisplay(pca_mi_scores)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:47.098468Z","iopub.execute_input":"2022-11-13T13:00:47.098793Z","iopub.status.idle":"2022-11-13T13:00:47.422362Z","shell.execute_reply.started":"2022-11-13T13:00:47.098744Z","shell.execute_reply":"2022-11-13T13:00:47.421092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_target_lag_lake_level_ratio = X_lag_features[:,0] + X_lag_features[:,2]\n\nsns.scatterplot(x=X_target_lag_lake_level_ratio, y=X_daily[\"FlowRate\"])\nplt.xlabel(\"Ratio of previous lake level and previous flow rate against today's flow rate\")\n\nplt.figure()\nsns.scatterplot(x=X_lag_features[:,0], y=X_daily[\"FlowRate\"])\nplt.xlabel(\"Previous day's flow rate\")","metadata":{"execution":{"iopub.status.busy":"2022-11-13T13:00:47.423522Z","iopub.execute_input":"2022-11-13T13:00:47.423826Z","iopub.status.idle":"2022-11-13T13:00:47.825846Z","shell.execute_reply.started":"2022-11-13T13:00:47.423801Z","shell.execute_reply":"2022-11-13T13:00:47.824680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This probably doesn't add huge amounts of new information, compared to simply plotting against the previous day's flow","metadata":{}}]}