{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "13083dab-ea68-4cec-90f5-20c5c523423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_json(data_url, record_path=['Data']):\n",
    "    content = requests.get(data_url).json()\n",
    "    df_all = pd.json_normalize(content,record_path=record_path)\n",
    "    \n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c4de1eaf-f687-445e-a6eb-6d261c211e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape webpage\n",
    "import io\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# Start date and end date\n",
    "today = date.today()\n",
    "start_date = '2020-01-01'\n",
    "end_date = date.today() - timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "57b9ab85-e85d-4d76-8c9c-e10b9c99cc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(293741, 2)\n",
      "                  TimeStamp   FlowRate\n",
      "0 2022-10-17 00:00:00+00:00  39.085441\n",
      "1 2022-10-16 23:55:00+00:00  38.851989\n",
      "2 2022-10-16 23:50:00+00:00  39.386349\n",
      "3 2022-10-16 23:45:00+00:00  39.152236\n",
      "4 2022-10-16 23:40:00+00:00  38.851989\n"
     ]
    }
   ],
   "source": [
    "# Get river data\n",
    "river_data_url = 'https://envdata.boprc.govt.nz/Data/DatasetGrid?dataset=35946&sort=TimeStamp-desc&page=1&group=&filter=&interval=Custom&timezone=720&date={}&endDate={}&calendar=1&alldata=false'.format(start_date, end_date)\n",
    "flow_df_all = get_df_from_json(river_data_url)\n",
    "flow_df = flow_df_all[[\"TimeStamp\", \"Value\"]]\n",
    "flow_df = flow_df.rename(columns={'Value': 'FlowRate'})\n",
    "flow_df['TimeStamp']= pd.to_datetime(flow_df['TimeStamp'])\n",
    "\n",
    "print(flow_df.shape)\n",
    "print(flow_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7d3b43e4-193d-4f11-8ad4-6708c848c162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(293824, 2)\n",
      "                  TimeStamp LakeLevel\n",
      "0 2022-10-17 00:00:00+00:00    279.19\n",
      "1 2022-10-16 23:55:00+00:00   279.186\n",
      "2 2022-10-16 23:50:00+00:00   279.178\n",
      "3 2022-10-16 23:45:00+00:00   279.178\n",
      "4 2022-10-16 23:40:00+00:00   279.182\n"
     ]
    }
   ],
   "source": [
    "# Get Lake levels\n",
    "lake_level_url = 'https://envdata.boprc.govt.nz/Data/DatasetGrid?dataset=32419&sort=TimeStamp-desc&page=1&group=&filter=&interval=Custom&timezone=720&date={}&endDate={}&calendar=1&alldata=false'.format(start_date, end_date)\n",
    "lake_level_df_all = get_df_from_json(lake_level_url)\n",
    "lake_level_df = lake_level_df_all[[\"TimeStamp\", \"Value\"]]\n",
    "lake_level_df = lake_level_df.rename(columns={'Value': 'LakeLevel'})\n",
    "lake_level_df['TimeStamp']= pd.to_datetime(lake_level_df['TimeStamp'])\n",
    "print(lake_level_df.shape)\n",
    "print(lake_level_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f32fb673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              TimeStamp   Gate1   Gate2   Gate3\n",
      "0  2022-10-18T10:40:00Z  1500.0  1500.0  1500.0\n",
      "1  2022-10-18T10:35:00Z  1500.0  1500.0  1500.0\n",
      "2  2022-10-18T10:30:00Z  1500.0  1500.0  1500.0\n",
      "3  2022-10-18T10:25:00Z  1500.0  1500.0  1500.0\n",
      "4  2022-10-18T10:20:00Z  1500.0  1500.0  1500.0\n"
     ]
    }
   ],
   "source": [
    "# Get gate levels\n",
    "#Gate 1\n",
    "gate_levels_url_1 = 'https://envdata.boprc.govt.nz/Data/DatasetGrid?dataset=38970&sort=TimeStamp-desc&page=1&pageSize=100&group=&filter=&interval=Latest&timezone=720&date={}&endDate={}&calendar=1&alldata=false'.format(start_date, end_date)\n",
    "gate_1_df = get_df_from_json(gate_levels_url_1)\n",
    "gate_1_df = gate_1_df[[\"TimeStamp\", \"Value\"]]\n",
    "gate_1_df = gate_1_df.rename(columns={\"Value\": \"Gate1\"})\n",
    "\n",
    "# Gate 2\n",
    "gate_levels_url_2 = 'https://envdata.boprc.govt.nz/Data/DatasetGrid?dataset=38973&sort=TimeStamp-desc&page=1&pageSize=100&group=&filter=&interval=Latest&timezone=720&date={}&endDate={}&calendar=1&alldata=false'.format(start_date, end_date)\n",
    "gate_2_df = get_df_from_json(gate_levels_url_2)\n",
    "gate_2_df = gate_2_df[[\"TimeStamp\", \"Value\"]]\n",
    "gate_2_df = gate_2_df.rename(columns={\"Value\": \"Gate2\"})\n",
    "\n",
    "# Gate 3\n",
    "gate_levels_url_3 = 'https://envdata.boprc.govt.nz/Data/DatasetGrid?dataset=38972&sort=TimeStamp-desc&page=1&pageSize=100&group=&filter=&interval=Latest&timezone=720&date={}&endDate={}&calendar=1&alldata=false'.format(start_date, end_date)\n",
    "gate_3_df = get_df_from_json(gate_levels_url_3)\n",
    "gate_3_df = gate_3_df[[\"TimeStamp\", \"Value\"]]\n",
    "gate_3_df = gate_3_df.rename(columns={\"Value\": \"Gate3\"})\n",
    "\n",
    "# Concatenate into single dataframe\n",
    "gate_levels_df_temp['TimeStamp']= pd.to_datetime(gate_levels_df_temp['TimeStamp'])\n",
    "gate_levels_df_temp = pd.merge(gate_1_df, gate_2_df, on='TimeStamp')\n",
    "gate_levels_df = pd.merge(gate_levels_df_temp, gate_3_df, on='TimeStamp', how='left')\n",
    "\n",
    "print(gate_levels_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e6085719-c90f-4742-9430-c3bda968c2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  TimeStamp  Rainfall\n",
      "0 2022-10-17 00:00:00+00:00       0.0\n",
      "1 2022-10-16 23:00:00+00:00       0.0\n",
      "2 2022-10-16 22:00:00+00:00       0.0\n",
      "3 2022-10-16 21:00:00+00:00       0.0\n",
      "4 2022-10-16 20:00:00+00:00       0.0\n",
      "(24481, 2)\n"
     ]
    }
   ],
   "source": [
    "# Get rainfall at Lake Rotoiti\n",
    "\n",
    "rainfall_url = 'https://envdata.boprc.govt.nz/Data/DatasetGrid?dataset=47928&sort=TimeStamp-desc&page=1&group=&filter=&interval=Custom&timezone=720&date={}&endDate={}&calendar=1&alldata=false'.format(start_date, end_date)\n",
    "rainfall_df_all = get_df_from_json(rainfall_url)\n",
    "rainfall_df = rainfall_df_all[[\"TimeStamp\", \"Value\"]]\n",
    "rainfall_df = rainfall_df.rename(columns={'Value': 'Rainfall'})\n",
    "rainfall_df['TimeStamp']= pd.to_datetime(rainfall_df['TimeStamp'])\n",
    "print(rainfall_df.head())\n",
    "print(rainfall_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "286790ba-02f4-4fca-8586-29281e9412f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on datetime64[ns, UTC] and object columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [124]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Merge datasets into one dataframe\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df_temp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(lake_level_df, flow_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimeStamp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m df_temp \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_temp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgate_levels_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTimeStamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m df_combined \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df_temp, rainfall_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimeStamp\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#Set index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:107\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m--> 107\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:704\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    696\u001b[0m (\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m    700\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 704\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1261\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m-> 1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on datetime64[ns, UTC] and object columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "# Merge datasets into one dataframe\n",
    "df_temp = pd.merge(lake_level_df, flow_df, on='TimeStamp')\n",
    "df_temp = pd.merge(df_temp, gate_levels_df, on='TimeStamp')\n",
    "df_combined = pd.merge(df_temp, rainfall_df, on='TimeStamp', how='left')\n",
    "\n",
    "#Set index\n",
    "df_combined['TimeStamp'] = pd.to_datetime(df_combined['TimeStamp'])\n",
    "df_combined.set_index('TimeStamp', inplace=True)\n",
    "\n",
    "#Remove rows for which we don't have rainfall data\n",
    "df_river_data = df_combined.dropna()\n",
    "\n",
    "#Sort by timestamp descending\n",
    "df_river_data = df_river_data.sort_values('TimeStamp')\n",
    "\n",
    "print (df_river_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fec87ac-9485-4ec5-9056-d68e2c07113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to csv\n",
    "df_river_data.to_csv('kaituna_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
